{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XI6kAvET4f95"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_entorno = [[None, 0],\n",
        "                [-100, 0],\n",
        "                [0, 0],\n",
        "                [0, 0],\n",
        "                [0, 0],\n",
        "                [0, 100],\n",
        "                [0, 0],\n",
        "                [100, 0],\n",
        "                [0, 0],\n",
        "                [0, None]]"
      ],
      "metadata": {
        "id": "tDn2IUPG7qtD"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_q = [[0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0],\n",
        "      [0, 0]]"
      ],
      "metadata": {
        "id": "-oejnX6p76Yf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estados_ganadores_perdedores = [0, 6]\n",
        "\n",
        "#devuelve una lista de acciones posibles desde una posición dada.\n",
        "def obtener_acciones_posibles(pos_actual):\n",
        "    matriz_pasos = [x is not None for x in matriz_entorno[pos_actual]]\n",
        "    acciones = []\n",
        "    if(matriz_pasos[0]):\n",
        "        acciones.append(0)\n",
        "    if(matriz_pasos[1]):\n",
        "        acciones.append(1)\n",
        "    return acciones\n",
        "#verifica si se alcanzó un estado objetivo dado una posición.\n",
        "def se_alcanzo_estado_objetivo(pos_actual):\n",
        "    return pos_actual in [6]\n",
        "\n",
        "#devuelve el siguiente estado después de tomar una acción desde una posición dada.\n",
        "def obtener_siguiente_estado(pos_actual, accion):\n",
        "    if (accion == 0):\n",
        "        return pos_actual - 1\n",
        "    else:\n",
        "        return pos_actual + 1\n",
        "\n",
        "#verifica si una posición dada es un estado final del juego.\n",
        "def es_fin_del_juego(pos_actual):\n",
        "    return pos_actual in estados_ganadores_perdedores\n",
        "\n",
        "#obtiene el camino optimo y la accion realizada\n",
        "def obtener_camino_optimo(matriz_q):\n",
        "    camino_optimo = []\n",
        "    pos_actual = 1\n",
        "\n",
        "    while not es_fin_del_juego(pos_actual):\n",
        "        acciones_posibles = obtener_acciones_posibles(pos_actual)\n",
        "        accion_optima = max(acciones_posibles, key=lambda x: matriz_q[pos_actual][x])\n",
        "        siguiente_estado = obtener_siguiente_estado(pos_actual, accion_optima)\n",
        "        camino_optimo.append((siguiente_estado, accion_optima))\n",
        "        pos_actual = siguiente_estado\n",
        "\n",
        "    return camino_optimo\n"
      ],
      "metadata": {
        "id": "PWoaSyiR8A6o"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descuento = 0.9\n",
        "tasa_aprendizaje = 0.5\n",
        "\n",
        "for _ in range(100):\n",
        "    # obtener posición inicial\n",
        "    pos_actual = random.choice([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "    # mientras no se alcance el estado objetivo\n",
        "    while(not es_fin_del_juego(pos_actual)):\n",
        "        # obtener todas las acciones posibles desde pos_actual\n",
        "        acciones_posibles = obtener_acciones_posibles(pos_actual)\n",
        "        # seleccionar una acción aleatoriamente\n",
        "        accion = random.choice(acciones_posibles)\n",
        "        # encontrar el siguiente estado correspondiente a la acción seleccionada\n",
        "        siguiente_estado = obtener_siguiente_estado(pos_actual, accion)\n",
        "        # actualizar la matriz Q\n",
        "        matriz_q[pos_actual][accion] = matriz_q[pos_actual][accion] + tasa_aprendizaje * (matriz_entorno[pos_actual][accion] +\n",
        "            descuento * max(matriz_q[siguiente_estado]) - matriz_q[pos_actual][accion])\n",
        "        # ir al siguiente estado\n",
        "        pos_actual = siguiente_estado\n",
        "    # imprimir estado\n",
        "    #print(\"Episodio \", _, \" completado\")\n",
        "\n",
        "\n",
        "camino_optimo = obtener_camino_optimo(matriz_q)\n",
        "# Imprimir el camino óptimo\n",
        "print(\"Camino óptimo:\", camino_optimo)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print(str(matriz_q[i]))\n",
        "print(\"Entrenamiento completado...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bkMt9qY8Coz",
        "outputId": "dbbb47a8-ec40-4e63-b06f-abdf823dc129"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Camino óptimo: [(2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]\n",
            "[0, 0]\n",
            "[-99.99909898376464, 65.61000000000001]\n",
            "[59.04901173198225, 72.9]\n",
            "[65.61041713714602, 81.0]\n",
            "[72.90012311339379, 90.0]\n",
            "[81.00000858306885, 100.0]\n",
            "[0, 0]\n",
            "[100.00000000242936, 81.0000000341043]\n",
            "[90.00000000938735, 72.90000001506164]\n",
            "[81.00000001140745, 0]\n",
            "Entrenamiento completado...\n"
          ]
        }
      ]
    }
  ]
}